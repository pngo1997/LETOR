{
 "cells": [

  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start-up -- **Load saved (and preprocessed) data from pickle files.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:51:24.371337Z",
     "iopub.status.busy": "2024-02-22T22:51:24.370691Z",
     "iopub.status.idle": "2024-02-22T22:51:24.747772Z",
     "shell.execute_reply": "2024-02-22T22:51:24.746763Z",
     "shell.execute_reply.started": "2024-02-22T22:51:24.371293Z"
    },
    "executionInfo": {
     "elapsed": 878,
     "status": "ok",
     "timestamp": 1703783246172,
     "user": {
      "displayName": "Noriko T",
      "userId": "06082512421306527471"
     },
     "user_tz": 360
    },
    "id": "x2FqiTeV7qYZ"
   },
   "outputs": [],
   "source": [
    "#Import libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0KmZOpf7qYa"
   },
   "source": [
    "### 1. Read saved (serialized) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T21:43:04.121316Z",
     "iopub.status.busy": "2024-02-22T21:43:04.120787Z",
     "iopub.status.idle": "2024-02-22T21:43:15.010500Z",
     "shell.execute_reply": "2024-02-22T21:43:15.009625Z",
     "shell.execute_reply.started": "2024-02-22T21:43:04.121284Z"
    },
    "executionInfo": {
     "elapsed": 19951,
     "status": "ok",
     "timestamp": 1703785853778,
     "user": {
      "displayName": "Noriko T",
      "userId": "06082512421306527471"
     },
     "user_tz": 360
    },
    "id": "zXtXlMek7qYa"
   },
   "outputs": [],
   "source": [
    "PATH = '../input/csc-575-hw5-winter-2024/'\n",
    "#Read train and test data.\n",
    "\n",
    "trainData = pd.read_pickle(f'{PATH}train_x.pkl')\n",
    "trainTarget = pd.read_pickle(f'{PATH}train_y.pkl')\n",
    "testData = pd.read_pickle(f'{PATH}test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data - train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T21:43:15.012277Z",
     "iopub.status.busy": "2024-02-22T21:43:15.011961Z",
     "iopub.status.idle": "2024-02-22T21:43:15.047758Z",
     "shell.execute_reply": "2024-02-22T21:43:15.046903Z",
     "shell.execute_reply.started": "2024-02-22T21:43:15.012250Z"
    },
    "executionInfo": {
     "elapsed": 94,
     "status": "ok",
     "timestamp": 1703785868278,
     "user": {
      "displayName": "Noriko T",
      "userId": "06082512421306527471"
     },
     "user_tz": 360
    },
    "id": "aXRizjPgjQLK",
    "outputId": "618927e0-5c09-465f-e4e0-2b222e54c6c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>product_title</th>\n",
       "      <th>search_term</th>\n",
       "      <th>product_description</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>100001</td>\n",
       "      <td>[simpson, strongti, 12gaug, angl]</td>\n",
       "      <td>[angl, bracket]</td>\n",
       "      <td>[angl, make, joint, stronger, also, provid, co...</td>\n",
       "      <td>[bullet01, versatil, connector, variou, 90, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100001</td>\n",
       "      <td>[simpson, strongti, 12gaug, angl]</td>\n",
       "      <td>[l, bracket]</td>\n",
       "      <td>[angl, make, joint, stronger, also, provid, co...</td>\n",
       "      <td>[bullet01, versatil, connector, variou, 90, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>100002</td>\n",
       "      <td>[behr, premium, textur, deckov, 1gal, sc141, t...</td>\n",
       "      <td>[deck]</td>\n",
       "      <td>[behr, premium, textur, deckov, innov, solid, ...</td>\n",
       "      <td>[applic, method, brushrollerspray, assembl, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>100005</td>\n",
       "      <td>[delta, vero, 1handl, shower, faucet, trim, ki...</td>\n",
       "      <td>[rain, shower, head]</td>\n",
       "      <td>[updat, bathroom, delta, vero, singlehandl, sh...</td>\n",
       "      <td>[bath, faucet, type, combo, tub, shower, built...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>100005</td>\n",
       "      <td>[delta, vero, 1handl, shower, faucet, trim, ki...</td>\n",
       "      <td>[shower, faucet]</td>\n",
       "      <td>[updat, bathroom, delta, vero, singlehandl, sh...</td>\n",
       "      <td>[bath, faucet, type, combo, tub, shower, built...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  product_uid                                      product_title  \\\n",
       "0   2       100001                  [simpson, strongti, 12gaug, angl]   \n",
       "1   3       100001                  [simpson, strongti, 12gaug, angl]   \n",
       "2   9       100002  [behr, premium, textur, deckov, 1gal, sc141, t...   \n",
       "3  16       100005  [delta, vero, 1handl, shower, faucet, trim, ki...   \n",
       "4  17       100005  [delta, vero, 1handl, shower, faucet, trim, ki...   \n",
       "\n",
       "            search_term                                product_description  \\\n",
       "0       [angl, bracket]  [angl, make, joint, stronger, also, provid, co...   \n",
       "1          [l, bracket]  [angl, make, joint, stronger, also, provid, co...   \n",
       "2                [deck]  [behr, premium, textur, deckov, innov, solid, ...   \n",
       "3  [rain, shower, head]  [updat, bathroom, delta, vero, singlehandl, sh...   \n",
       "4      [shower, faucet]  [updat, bathroom, delta, vero, singlehandl, sh...   \n",
       "\n",
       "                                          attributes  \n",
       "0  [bullet01, versatil, connector, variou, 90, co...  \n",
       "1  [bullet01, versatil, connector, variou, 90, co...  \n",
       "2  [applic, method, brushrollerspray, assembl, de...  \n",
       "3  [bath, faucet, type, combo, tub, shower, built...  \n",
       "4  [bath, faucet, type, combo, tub, shower, built...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One product matches against different searches.\n",
    "#Product title, description, attribute are originally string, applied stemming and tokenization.\n",
    "trainData.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data - train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T21:43:17.878162Z",
     "iopub.status.busy": "2024-02-22T21:43:17.877813Z",
     "iopub.status.idle": "2024-02-22T21:43:17.886192Z",
     "shell.execute_reply": "2024-02-22T21:43:17.885035Z",
     "shell.execute_reply.started": "2024-02-22T21:43:17.878135Z"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1703785887812,
     "user": {
      "displayName": "Noriko T",
      "userId": "06082512421306527471"
     },
     "user_tz": 360
    },
    "id": "vsffCXH6jVzE",
    "outputId": "28153297-5eac-4ca9-cc02-a892c8d7bd0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3.00\n",
       "1    2.50\n",
       "2    3.00\n",
       "3    2.33\n",
       "4    2.67\n",
       "Name: relevance, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Relevance score for each search - item combo.\n",
    "trainTarget.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data - test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T21:43:20.039057Z",
     "iopub.status.busy": "2024-02-22T21:43:20.038170Z",
     "iopub.status.idle": "2024-02-22T21:43:20.066154Z",
     "shell.execute_reply": "2024-02-22T21:43:20.065184Z",
     "shell.execute_reply.started": "2024-02-22T21:43:20.039023Z"
    },
    "executionInfo": {
     "elapsed": 89,
     "status": "ok",
     "timestamp": 1703785900216,
     "user": {
      "displayName": "Noriko T",
      "userId": "06082512421306527471"
     },
     "user_tz": 360
    },
    "id": "0t6ZbsyZjZBY",
    "outputId": "4c616c92-68a9-4334-9f11-ce7609f5763b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>product_title</th>\n",
       "      <th>search_term</th>\n",
       "      <th>product_description</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>100001</td>\n",
       "      <td>[simpson, strongti, 12gaug, angl]</td>\n",
       "      <td>[metal, l, bracket]</td>\n",
       "      <td>[angl, make, joint, stronger, also, provid, co...</td>\n",
       "      <td>[bullet01, versatil, connector, variou, 90, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>100001</td>\n",
       "      <td>[simpson, strongti, 12gaug, angl]</td>\n",
       "      <td>[simpson, sku, abl]</td>\n",
       "      <td>[angl, make, joint, stronger, also, provid, co...</td>\n",
       "      <td>[bullet01, versatil, connector, variou, 90, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>100001</td>\n",
       "      <td>[simpson, strongti, 12gaug, angl]</td>\n",
       "      <td>[simpson, strong, tie]</td>\n",
       "      <td>[angl, make, joint, stronger, also, provid, co...</td>\n",
       "      <td>[bullet01, versatil, connector, variou, 90, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>100001</td>\n",
       "      <td>[simpson, strongti, 12gaug, angl]</td>\n",
       "      <td>[simpson, strong, tie, hcc668]</td>\n",
       "      <td>[angl, make, joint, stronger, also, provid, co...</td>\n",
       "      <td>[bullet01, versatil, connector, variou, 90, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>100003</td>\n",
       "      <td>[sterl, ensembl, 3314, x, 60, x, 7514, bath, s...</td>\n",
       "      <td>[bath, shower, kit]</td>\n",
       "      <td>[classic, architectur, meet, contemporari, des...</td>\n",
       "      <td>[builtin, flang, ye, bullet01, slightli, narro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  product_uid                                      product_title  \\\n",
       "0   4       100001                  [simpson, strongti, 12gaug, angl]   \n",
       "1   5       100001                  [simpson, strongti, 12gaug, angl]   \n",
       "2   6       100001                  [simpson, strongti, 12gaug, angl]   \n",
       "3   7       100001                  [simpson, strongti, 12gaug, angl]   \n",
       "4  10       100003  [sterl, ensembl, 3314, x, 60, x, 7514, bath, s...   \n",
       "\n",
       "                      search_term  \\\n",
       "0             [metal, l, bracket]   \n",
       "1             [simpson, sku, abl]   \n",
       "2          [simpson, strong, tie]   \n",
       "3  [simpson, strong, tie, hcc668]   \n",
       "4             [bath, shower, kit]   \n",
       "\n",
       "                                 product_description  \\\n",
       "0  [angl, make, joint, stronger, also, provid, co...   \n",
       "1  [angl, make, joint, stronger, also, provid, co...   \n",
       "2  [angl, make, joint, stronger, also, provid, co...   \n",
       "3  [angl, make, joint, stronger, also, provid, co...   \n",
       "4  [classic, architectur, meet, contemporari, des...   \n",
       "\n",
       "                                          attributes  \n",
       "0  [bullet01, versatil, connector, variou, 90, co...  \n",
       "1  [bullet01, versatil, connector, variou, 90, co...  \n",
       "2  [bullet01, versatil, connector, variou, 90, co...  \n",
       "3  [bullet01, versatil, connector, variou, 90, co...  \n",
       "4  [builtin, flang, ye, bullet01, slightli, narro...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Same format as train data x.\n",
    "testData.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_Ezqlm2ROVx"
   },
   "source": [
    "## ---Start the homework--- \n",
    "### Goal: Create prediction system on relevance score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Train Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dictionary word count of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T21:43:23.266862Z",
     "iopub.status.busy": "2024-02-22T21:43:23.266165Z",
     "iopub.status.idle": "2024-02-22T21:43:28.459467Z",
     "shell.execute_reply": "2024-02-22T21:43:28.458496Z",
     "shell.execute_reply.started": "2024-02-22T21:43:23.266829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_uid</th>\n",
       "      <th>product_title_wcDict</th>\n",
       "      <th>search_term_wcDict</th>\n",
       "      <th>product_description_wcDict</th>\n",
       "      <th>attributes_wcDict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>{'simpson': 1, 'strongti': 1, '12gaug': 1, 'an...</td>\n",
       "      <td>{'angl': 1, 'bracket': 1}</td>\n",
       "      <td>{'angl': 3, 'make': 1, 'joint': 2, 'stronger':...</td>\n",
       "      <td>{'bullet01': 1, 'versatil': 1, 'connector': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>{'simpson': 1, 'strongti': 1, '12gaug': 1, 'an...</td>\n",
       "      <td>{'l': 1, 'bracket': 1}</td>\n",
       "      <td>{'angl': 3, 'make': 1, 'joint': 2, 'stronger':...</td>\n",
       "      <td>{'bullet01': 1, 'versatil': 1, 'connector': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>{'behr': 1, 'premium': 1, 'textur': 1, 'deckov...</td>\n",
       "      <td>{'deck': 1}</td>\n",
       "      <td>{'behr': 3, 'premium': 1, 'textur': 2, 'deckov...</td>\n",
       "      <td>{'applic': 1, 'method': 1, 'brushrollerspray':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100005</td>\n",
       "      <td>{'delta': 1, 'vero': 1, '1handl': 1, 'shower':...</td>\n",
       "      <td>{'rain': 1, 'shower': 1, 'head': 1}</td>\n",
       "      <td>{'updat': 1, 'bathroom': 1, 'delta': 1, 'vero'...</td>\n",
       "      <td>{'bath': 2, 'faucet': 6, 'type': 4, 'combo': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>{'delta': 1, 'vero': 1, '1handl': 1, 'shower':...</td>\n",
       "      <td>{'shower': 1, 'faucet': 1}</td>\n",
       "      <td>{'updat': 1, 'bathroom': 1, 'delta': 1, 'vero'...</td>\n",
       "      <td>{'bath': 2, 'faucet': 6, 'type': 4, 'combo': 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_uid                               product_title_wcDict  \\\n",
       "0       100001  {'simpson': 1, 'strongti': 1, '12gaug': 1, 'an...   \n",
       "1       100001  {'simpson': 1, 'strongti': 1, '12gaug': 1, 'an...   \n",
       "2       100002  {'behr': 1, 'premium': 1, 'textur': 1, 'deckov...   \n",
       "3       100005  {'delta': 1, 'vero': 1, '1handl': 1, 'shower':...   \n",
       "4       100005  {'delta': 1, 'vero': 1, '1handl': 1, 'shower':...   \n",
       "\n",
       "                    search_term_wcDict  \\\n",
       "0            {'angl': 1, 'bracket': 1}   \n",
       "1               {'l': 1, 'bracket': 1}   \n",
       "2                          {'deck': 1}   \n",
       "3  {'rain': 1, 'shower': 1, 'head': 1}   \n",
       "4           {'shower': 1, 'faucet': 1}   \n",
       "\n",
       "                          product_description_wcDict  \\\n",
       "0  {'angl': 3, 'make': 1, 'joint': 2, 'stronger':...   \n",
       "1  {'angl': 3, 'make': 1, 'joint': 2, 'stronger':...   \n",
       "2  {'behr': 3, 'premium': 1, 'textur': 2, 'deckov...   \n",
       "3  {'updat': 1, 'bathroom': 1, 'delta': 1, 'vero'...   \n",
       "4  {'updat': 1, 'bathroom': 1, 'delta': 1, 'vero'...   \n",
       "\n",
       "                                   attributes_wcDict  \n",
       "0  {'bullet01': 1, 'versatil': 1, 'connector': 1,...  \n",
       "1  {'bullet01': 1, 'versatil': 1, 'connector': 1,...  \n",
       "2  {'applic': 1, 'method': 1, 'brushrollerspray':...  \n",
       "3  {'bath': 2, 'faucet': 6, 'type': 4, 'combo': 1...  \n",
       "4  {'bath': 2, 'faucet': 6, 'type': 4, 'combo': 1...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData_dict = trainData\n",
    "\n",
    "convertColumns = ['product_title', 'search_term', 'product_description', 'attributes']\n",
    "\n",
    "for column in convertColumns:\n",
    "    #Convert each cell ito a dictionary of word counts.\n",
    "    trainData_dict[column + '_wcDict'] = trainData_dict[column].apply(lambda x: dict(Counter(x)))\n",
    "\n",
    "#Drop original columns.\n",
    "trainData_dict = trainData_dict.drop(columns=['id', 'product_title', 'search_term', 'product_description', 'attributes'])\n",
    "trainData_dict.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRODUCT DATA\n",
    "### Check if one product has different title? --> IT DOES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T21:43:50.684420Z",
     "iopub.status.busy": "2024-02-22T21:43:50.683739Z",
     "iopub.status.idle": "2024-02-22T21:43:53.988385Z",
     "shell.execute_reply": "2024-02-22T21:43:53.987394Z",
     "shell.execute_reply.started": "2024-02-22T21:43:50.684388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not all product_title_wcDict are the same for product_uid 100540\n",
      "Not all product_title_wcDict are the same for product_uid 101052\n",
      "Not all product_title_wcDict are the same for product_uid 101317\n",
      "Not all product_title_wcDict are the same for product_uid 101549\n",
      "Not all product_title_wcDict are the same for product_uid 102458\n",
      "Not all product_title_wcDict are the same for product_uid 105240\n",
      "Not all product_title_wcDict are the same for product_uid 122733\n",
      "Not all product_title_wcDict are the same for product_uid 126511\n",
      "Not all product_title_wcDict are the same for product_uid 131132\n",
      "Not all product_title_wcDict are the same for product_uid 136763\n",
      "Not all product_title_wcDict are the same for product_uid 137331\n",
      "Not all product_title_wcDict are the same for product_uid 138513\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "#Group the dataframe by 'product_uid' and iterate through each group.\n",
    "for name, group in trainData_dict.groupby('product_uid'):\n",
    "    #Check if all rows in the group have the same dictionary length and the same keys and values.\n",
    "    wc_dicts = group['product_title_wcDict'].tolist()\n",
    "    if all(wc_dict == wc_dicts[0] for wc_dict in wc_dicts):\n",
    "        counter += 0\n",
    "    else:\n",
    "        print(f\"Not all {'product_title_wcDict'} are the same for product_uid {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T21:44:26.300930Z",
     "iopub.status.busy": "2024-02-22T21:44:26.300575Z",
     "iopub.status.idle": "2024-02-22T21:44:26.308375Z",
     "shell.execute_reply": "2024-02-22T21:44:26.307340Z",
     "shell.execute_reply.started": "2024-02-22T21:44:26.300902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1light', 'oil', 'rub', 'bronz', 'adjust', 'mini', 'pendant']\n",
      "['1light', 'oilrub', 'bronz', 'adjust', 'mini', 'pendant']\n",
      "['1light', 'oilrub', 'bronz', 'adjust', 'mini', 'pendant']\n"
     ]
    }
   ],
   "source": [
    "#Original train data.\n",
    "filteredRows = trainData[trainData['product_uid'] == 101052]\n",
    "for wc_dict in filteredRows['product_title']:\n",
    "    print(wc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T21:45:01.810096Z",
     "iopub.status.busy": "2024-02-22T21:45:01.809384Z",
     "iopub.status.idle": "2024-02-22T21:45:01.817080Z",
     "shell.execute_reply": "2024-02-22T21:45:01.816022Z",
     "shell.execute_reply.started": "2024-02-22T21:45:01.810066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1light': 1, 'oil': 1, 'rub': 1, 'bronz': 1, 'adjust': 1, 'mini': 1, 'pendant': 1}\n",
      "{'1light': 1, 'oilrub': 1, 'bronz': 1, 'adjust': 1, 'mini': 1, 'pendant': 1}\n",
      "{'1light': 1, 'oilrub': 1, 'bronz': 1, 'adjust': 1, 'mini': 1, 'pendant': 1}\n"
     ]
    }
   ],
   "source": [
    "#Dictionary train data.\n",
    "filteredRows2 = trainData_dict[trainData_dict['product_uid'] == 101052]\n",
    "for wc_dict in filteredRows2['product_title_wcDict']:\n",
    "    print(wc_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert PRODUCT columns to inverted index dictionaries. \n",
    "#### Note: There are same product with multiple rows in the train data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:24:32.637608Z",
     "iopub.status.busy": "2024-02-22T22:24:32.636947Z",
     "iopub.status.idle": "2024-02-22T22:25:12.208301Z",
     "shell.execute_reply": "2024-02-22T22:25:12.207299Z",
     "shell.execute_reply.started": "2024-02-22T22:24:32.637575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique product: 54667\n",
      "Total number of unique product: 54667\n",
      "Total number of unique product: 54667\n"
     ]
    }
   ],
   "source": [
    "def calculateIDF(productFrequency, total_uniqueProduct):\n",
    "    '''Calculate IDF for for inverted index.'''\n",
    "    \n",
    "    #Using log base 10.\n",
    "    return {term: math.log10(total_uniqueProduct / frequency) for term, frequency in productFrequency.items()}\n",
    "\n",
    "def generate_invIndex(column, data):\n",
    "    '''Generate inverted index dictionary for input column in train Data.'''\n",
    "    \n",
    "    #N is the total number of unique products in the corpus.\n",
    "    total_uniqueProduct = len(data['product_uid'].unique())  \n",
    "    print(f'Total number of unique product: {total_uniqueProduct}')\n",
    "    \n",
    "    invertedIndex = {}\n",
    "    productFrequency = Counter()\n",
    "       \n",
    "    for index, row in data.iterrows():\n",
    "        #Get the TOTAL occurences of each term within the column. \n",
    "        terms = set(row[column].keys())  #Use terms of the wc dictionary as keys.\n",
    "        #A term in multiple rows within the same product ID.\n",
    "        #Count for that term will be incremented accordingly. \n",
    "        productFrequency.update(terms)\n",
    "    idfTerm = calculateIDF(productFrequency, total_uniqueProduct)\n",
    "    \n",
    "    #Dictionary for inverted index {term as key | tuple(idf, list of postings) as value}.\n",
    "    #idf: of a term in the entire respective column corpus. JUST THE IDF!!! -- \n",
    "    #List of postings: element is individual dictionary {'product_uid' as keys | raw term frequency as value}. \n",
    "    for term, idf in idfTerm.items():\n",
    "        invertedIndex[term] = (idf, {})\n",
    "        \n",
    "    #Create posting list for each term.\n",
    "    for index, row in data.iterrows():\n",
    "        productID = row['product_uid']\n",
    "        termFrequency = row.get(column, {})\n",
    "        for term in sorted(termFrequency.keys()):\n",
    "            if productID in invertedIndex[term][1]:\n",
    "                invertedIndex[term][1][productID] += termFrequency[term]\n",
    "            else:\n",
    "                invertedIndex[term][1][productID] = termFrequency[term]\n",
    "    return invertedIndex\n",
    "\n",
    "#Generate inverted index for each product column.\n",
    "title_invIndex_train = generate_invIndex('product_title_wcDict', trainData_dict)\n",
    "descr_invIndex_train = generate_invIndex('product_description_wcDict', trainData_dict)\n",
    "attributes_invIndex_train = generate_invIndex('attributes_wcDict', trainData_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:25:31.820805Z",
     "iopub.status.busy": "2024-02-22T22:25:31.820450Z",
     "iopub.status.idle": "2024-02-22T22:25:31.825783Z",
     "shell.execute_reply": "2024-02-22T22:25:31.824792Z",
     "shell.execute_reply.started": "2024-02-22T22:25:31.820775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Title Inverted Index - train data:\n",
      "(2.9453335519587927, {100001: 2, 100664: 1, 100995: 6, 101245: 3, 102436: 2, 103250: 1, 103421: 1, 106751: 1, 107640: 2, 109015: 3, 109059: 1, 109196: 1, 112832: 2, 114423: 4, 117545: 1, 122392: 1, 129059: 3, 130474: 2, 130561: 1, 131312: 2, 131566: 1, 133917: 1, 134551: 1, 137719: 1, 137817: 2, 142111: 1, 143504: 1, 144302: 1, 146362: 2, 149416: 2, 152794: 2, 160934: 1, 163592: 1, 173816: 1, 188206: 1, 189166: 1, 192376: 1, 203565: 1})\n"
     ]
    }
   ],
   "source": [
    "#Get inverted index of the word '12aug' with respect to Title column.\n",
    "print(\"Product Title Inverted Index - train data:\")\n",
    "print(title_invIndex_train['12gaug'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:26:20.452340Z",
     "iopub.status.busy": "2024-02-22T22:26:20.451606Z",
     "iopub.status.idle": "2024-02-22T22:26:20.457156Z",
     "shell.execute_reply": "2024-02-22T22:26:20.456198Z",
     "shell.execute_reply.started": "2024-02-22T22:26:20.452309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Description Inverted Index - train data:\n",
      "(2.5645389730447725, {100001: 2, 100102: 2, 100398: 1, 100664: 1, 100842: 6, 100856: 1, 100976: 1, 100995: 6, 101070: 6, 102083: 3, 103250: 1, 103421: 1, 104919: 1, 105314: 1, 106344: 1, 106751: 1, 107078: 2, 107640: 2, 107740: 6, 108564: 2, 108957: 1, 109059: 1, 109760: 2, 110363: 1, 110978: 2, 112582: 2, 112832: 2, 112889: 1, 113278: 1, 114423: 4, 114970: 1, 116356: 1, 117384: 1, 117485: 4, 117522: 2, 117545: 1, 119222: 4, 119637: 2, 119694: 2, 120428: 4, 121229: 2, 123547: 1, 123576: 1, 123879: 2, 125728: 2, 127165: 1, 127729: 2, 127813: 1, 127978: 2, 128127: 1, 129059: 3, 130474: 2, 130561: 1, 131312: 2, 131566: 1, 132504: 1, 133917: 1, 134889: 1, 136031: 1, 137498: 1, 137539: 1, 137719: 1, 139264: 2, 139579: 1, 141160: 2, 141529: 2, 143688: 1, 144302: 1, 145654: 1, 145677: 2, 146362: 2, 146823: 2, 148201: 1, 148411: 1, 148651: 1, 149416: 2, 151534: 2, 152794: 6, 153932: 1, 154149: 1, 154417: 1, 156529: 1, 156701: 1, 163301: 1, 166771: 1, 167253: 1, 169926: 1, 173775: 1, 178912: 1, 181446: 1, 182685: 1, 187058: 1, 187068: 1, 187441: 1, 188114: 1, 189166: 1, 190619: 1, 192376: 1, 193198: 1, 193877: 2, 194150: 1, 197617: 2, 198770: 1, 199470: 1, 202836: 1})\n"
     ]
    }
   ],
   "source": [
    "#Get inverted index of the word '12aug' with respect to Description column.\n",
    "print(\"Product Description Inverted Index - train data:\")\n",
    "print(descr_invIndex_train['12gaug'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:28:01.626968Z",
     "iopub.status.busy": "2024-02-22T22:28:01.626271Z",
     "iopub.status.idle": "2024-02-22T22:28:01.631771Z",
     "shell.execute_reply": "2024-02-22T22:28:01.630856Z",
     "shell.execute_reply.started": "2024-02-22T22:28:01.626937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Attributes Inverted Index - train data:\n",
      "(2.684646797973627, {100001: 2, 100102: 2, 100664: 1, 100842: 3, 100856: 1, 100995: 6, 101070: 6, 102005: 1, 102083: 2, 103250: 1, 103421: 1, 104919: 1, 106344: 1, 107078: 2, 107517: 1, 107640: 2, 107740: 3, 107766: 2, 108564: 2, 112582: 2, 112832: 2, 112889: 1, 113278: 1, 114423: 4, 114970: 1, 117485: 4, 117522: 2, 119222: 4, 119637: 1, 121229: 2, 123547: 1, 125728: 2, 127165: 1, 127978: 2, 129059: 3, 130474: 2, 130561: 1, 131312: 2, 137498: 1, 139052: 2, 141529: 1, 144415: 2, 145654: 1, 146362: 2, 146799: 1, 146823: 2, 149416: 2, 152478: 2, 152794: 4, 154149: 1, 156405: 1, 156701: 1, 166771: 1, 167100: 2, 167253: 1, 173292: 1, 173775: 1, 181446: 1, 182685: 1, 187058: 1, 187068: 1, 188114: 1, 189166: 1, 192376: 1, 193877: 1, 194150: 1, 197617: 1, 198770: 1, 202836: 1})\n"
     ]
    }
   ],
   "source": [
    "#Get inverted index of the word 'bullet01' with respect to Attributes column.\n",
    "#Notice:'bullet01' has negative idf - tf term occurance > N document number. \n",
    "print(\"Product Attributes Inverted Index - train data:\")\n",
    "print(attributes_invIndex_train['12gaug'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute component vector length for each PRODUCT column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:29:45.038042Z",
     "iopub.status.busy": "2024-02-22T22:29:45.037084Z",
     "iopub.status.idle": "2024-02-22T22:29:48.520933Z",
     "shell.execute_reply": "2024-02-22T22:29:48.519943Z",
     "shell.execute_reply.started": "2024-02-22T22:29:45.038006Z"
    }
   },
   "outputs": [],
   "source": [
    "def computeVectorLength_product(invIndex):\n",
    "    '''Compute the component vector length for a product column.'''\n",
    "    vectorLengths = {}\n",
    "    \n",
    "    for term,(idfValue, productID_frequency) in invIndex.items():\n",
    "        for productID, tf in productID_frequency.items():\n",
    "            if productID not in vectorLengths:\n",
    "                vectorLengths[productID] = 0\n",
    "                \n",
    "            #Accumulate square of individual tf-idf.\n",
    "            vectorLengths[productID] += math.pow((idfValue * tf), 2.0)\n",
    "    \n",
    "    #Sqrt of sum value of each productID.\n",
    "    for productID in vectorLengths:\n",
    "        vectorLengths[productID] = math.sqrt(vectorLengths[productID])\n",
    "    \n",
    "    return vectorLengths\n",
    "\n",
    "#Get vector length for each product column.\n",
    "title_vecLength_train = computeVectorLength_product(title_invIndex_train)\n",
    "descr_vecLength_train = computeVectorLength_product(descr_invIndex_train)\n",
    "attributes_vecLength_train = computeVectorLength_product(attributes_invIndex_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:29:51.208887Z",
     "iopub.status.busy": "2024-02-22T22:29:51.208272Z",
     "iopub.status.idle": "2024-02-22T22:29:51.214026Z",
     "shell.execute_reply": "2024-02-22T22:29:51.212600Z",
     "shell.execute_reply.started": "2024-02-22T22:29:51.208857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Title Vector Length - train data:\n",
      "9.716528834416671\n"
     ]
    }
   ],
   "source": [
    "print(\"Product Title Vector Length - train data:\")\n",
    "print(title_vecLength_train[100001])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEARCH DATA\n",
    "### Convert SEARCH column to inverted index dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:36:23.396190Z",
     "iopub.status.busy": "2024-02-22T22:36:23.395492Z",
     "iopub.status.idle": "2024-02-22T22:36:37.517956Z",
     "shell.execute_reply": "2024-02-22T22:36:37.516911Z",
     "shell.execute_reply.started": "2024-02-22T22:36:23.396156Z"
    }
   },
   "outputs": [],
   "source": [
    "def tf_idfSearch(product_invertedIndex, data):\n",
    "    '''Compute the TF-IDF values for a search term dictionary with respect to a specific product column.\n",
    "    Returns: A dictionary containing TF-IDF values for each term in the search term dictionary.'''\n",
    "    \n",
    "    #Dictionary accumulate term frequency across all rows. \n",
    "    tfDict = {}  \n",
    "    \n",
    "    #Dictionary for tf-idf search {row index as key (start as 0) | dictionary(term, tf-idf) as value}.\n",
    "    tf_idfSearch = {}\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        #Retrieve the search term dictionary and productID for the current row.\n",
    "        search_termDict = row['search_term_wcDict']\n",
    "        productID = row['product_uid']\n",
    "\n",
    "        #Accumulate term frequency for each term across all rows in the 'search_term_wcDict' column.\n",
    "        for term, raw_tf in search_termDict.items():\n",
    "            tfDict[term] = tfDict.get(term, 0) + raw_tf\n",
    "        \n",
    "        #TF-IDF dictionary for each search row.\n",
    "        tf_idfRow = {}\n",
    "\n",
    "        #Iterate over each term in the search term dictionary.\n",
    "        for term, raw_tf in search_termDict.items():\n",
    "            \n",
    "            #Check if the term exists in the inverted index.\n",
    "            if term in product_invertedIndex:\n",
    "                \n",
    "                #Retrieve the respective IDF and posting list.\n",
    "                termIDF, postingList = product_invertedIndex[term]\n",
    "\n",
    "                #Check if the productID is in the posting list.\n",
    "                if productID in postingList:\n",
    "                    #Retrieve the count of the productID in the posting list.\n",
    "                    product_termCount = postingList[productID]\n",
    "\n",
    "                    #Calculate the weight of the term in the search term.\n",
    "                    weight = tfDict[term] * termIDF\n",
    "\n",
    "                    #Compute TF-IDF value for the term and store it in tf_idfRow dictionary.\n",
    "                    tf_idfRow[term] = weight * termIDF * product_termCount\n",
    "\n",
    "        #Store the TF-IDF result for the current row.\n",
    "        tf_idfSearch[index] = tf_idfRow\n",
    "    \n",
    "    return tf_idfSearch\n",
    "\n",
    "#Get search tf-idf with respect to each product column.\n",
    "title_tf_idfSearch_train = tf_idfSearch(title_invIndex_train, trainData_dict)\n",
    "descr_tf_idfSearch_train = tf_idfSearch(descr_invIndex_train, trainData_dict)\n",
    "attributes_tf_idfSearch_train = tf_idfSearch(attributes_invIndex_train, trainData_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute SEARCH score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:37:54.942092Z",
     "iopub.status.busy": "2024-02-22T22:37:54.941704Z",
     "iopub.status.idle": "2024-02-22T22:37:55.073153Z",
     "shell.execute_reply": "2024-02-22T22:37:55.072343Z",
     "shell.execute_reply.started": "2024-02-22T22:37:54.942060Z"
    }
   },
   "outputs": [],
   "source": [
    "def product_searchScore(tf_idfSearch):\n",
    "    '''Compute search score for each search against each product column.'''\n",
    "    \n",
    "    product_searchScore = {}\n",
    "    for index, term_tf_idf in tf_idfSearch.items():\n",
    "        #If empty dictionary - no mutual terms. Score is 0.  \n",
    "        if len(term_tf_idf) == 0:\n",
    "            product_searchScore[index] = 0\n",
    "        else:\n",
    "            score = sum(term_tf_idf.values())\n",
    "            product_searchScore[index] = score\n",
    "    \n",
    "    return product_searchScore                \n",
    "\n",
    "#Get search score tf-idf with respect to each product column.\n",
    "title_searchScore_train = product_searchScore(title_tf_idfSearch_train)\n",
    "descr_searchScore_train = product_searchScore(descr_tf_idfSearch_train)\n",
    "attributes_searchScore_train = product_searchScore(attributes_tf_idfSearch_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:39:04.384311Z",
     "iopub.status.busy": "2024-02-22T22:39:04.383511Z",
     "iopub.status.idle": "2024-02-22T22:39:04.390618Z",
     "shell.execute_reply": "2024-02-22T22:39:04.389690Z",
     "shell.execute_reply.started": "2024-02-22T22:39:04.384282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Title Search score - train data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1225.6014493684163"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Product Title Search score - train data:\")\n",
    "title_searchScore_train[74066]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute component vector length of SEARCH column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:39:06.783039Z",
     "iopub.status.busy": "2024-02-22T22:39:06.782311Z",
     "iopub.status.idle": "2024-02-22T22:39:07.024499Z",
     "shell.execute_reply": "2024-02-22T22:39:07.023672Z",
     "shell.execute_reply.started": "2024-02-22T22:39:06.783008Z"
    }
   },
   "outputs": [],
   "source": [
    "def computeVectorLength_search(tf_idfSearch):\n",
    "    '''Compute the component vector length for a column.'''\n",
    "    \n",
    "    vectorLengths = {}\n",
    "    \n",
    "    for index, term_tf_idf in tf_idfSearch.items():\n",
    "        search_tf_idfSq = 0.0\n",
    "        \n",
    "        #Iterate over each term in the query and calculate the squared sum\n",
    "        for term, tf_idfTerm in term_tf_idf.items():\n",
    "            search_tf_idfSq += math.pow(tf_idfTerm, 2.0)\n",
    "        #Take the square root of the squared sum\n",
    "        vectorLengths[index] = math.sqrt(search_tf_idfSq)\n",
    "\n",
    "    return vectorLengths\n",
    "\n",
    "#Get vector length of each tf-idf search, respect to each product column.\n",
    "title_search_vecLength_train = computeVectorLength_search(title_tf_idfSearch_train)\n",
    "descr_search_vecLength_train = computeVectorLength_search(descr_tf_idfSearch_train)\n",
    "attributes_search_vecLength_train = computeVectorLength_search(attributes_tf_idfSearch_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:39:20.218225Z",
     "iopub.status.busy": "2024-02-22T22:39:20.217486Z",
     "iopub.status.idle": "2024-02-22T22:39:20.223877Z",
     "shell.execute_reply": "2024-02-22T22:39:20.222890Z",
     "shell.execute_reply.started": "2024-02-22T22:39:20.218193Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74067"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make sure dictionary generated properly, len = total number of rows. \n",
    "len(title_search_vecLength_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarities.\n",
    "### Compute Cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:40:01.209757Z",
     "iopub.status.busy": "2024-02-22T22:40:01.209385Z",
     "iopub.status.idle": "2024-02-22T22:40:04.784539Z",
     "shell.execute_reply": "2024-02-22T22:40:04.783729Z",
     "shell.execute_reply.started": "2024-02-22T22:40:01.209727Z"
    }
   },
   "outputs": [],
   "source": [
    "def cosineSimilarity(search_vecLength, product_vecLength,tf_idf_searchScore, data):\n",
    "    '''Compute Cosine similarity between search and a product column.'''\n",
    "    \n",
    "    cosineSim_scoreDict = {}\n",
    "    #Iterate over each query in tf_idfQueries.\n",
    "    for index, product_search_score in tf_idf_searchScore.items(): \n",
    "        \n",
    "        productID = data.loc[index, 'product_uid']\n",
    "        productLength = product_vecLength.get(productID, 0.0)\n",
    "        \n",
    "        searchLength = search_vecLength[index]\n",
    "        \n",
    "        if productLength > 0 and searchLength > 0:\n",
    "            #Cosine similarity score.\n",
    "            cosineSim = product_search_score / (productLength * searchLength)\n",
    "            cosineSim_scoreDict[index] = cosineSim\n",
    "        else:\n",
    "            cosineSim_scoreDict[index] = 0.0\n",
    "    return cosineSim_scoreDict\n",
    "            \n",
    "#Get cosine similarity of each tf-idf search with each product column.\n",
    "title_cosineSim_train = cosineSimilarity(title_search_vecLength_train, title_vecLength_train,title_searchScore_train, trainData_dict)\n",
    "descr_cosineSim_train = cosineSimilarity(descr_search_vecLength_train, descr_vecLength_train, descr_searchScore_train, trainData_dict)\n",
    "attributes_cosineSim_train = cosineSimilarity(attributes_search_vecLength_train,attributes_vecLength_train, attributes_searchScore_train, trainData_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Jaccard similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:40:40.983599Z",
     "iopub.status.busy": "2024-02-22T22:40:40.982789Z",
     "iopub.status.idle": "2024-02-22T22:40:55.965432Z",
     "shell.execute_reply": "2024-02-22T22:40:55.964482Z",
     "shell.execute_reply.started": "2024-02-22T22:40:40.983565Z"
    }
   },
   "outputs": [],
   "source": [
    "def jaccardSimilarity(productColumn, data):\n",
    "    '''Compute Jaccard Similarity between search and a product column.'''\n",
    "    \n",
    "    jaccard_scoreDict = {}\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        productTerms = set(row[productColumn].keys())\n",
    "        searchTerms = set(row['search_term_wcDict'].keys())\n",
    "\n",
    "        #Calculate Jaccard Similarity. \n",
    "        intersectionSize = len(searchTerms.intersection(productTerms))\n",
    "        unionSize = len(searchTerms.union(productTerms))\n",
    "\n",
    "        if unionSize > 0:\n",
    "            jaccardScore = intersectionSize / unionSize\n",
    "            jaccard_scoreDict[index] = jaccardScore\n",
    "        else:\n",
    "            jaccard_scoreDict[index] = 0.0\n",
    "\n",
    "    return jaccard_scoreDict\n",
    "\n",
    "\n",
    "#Get jaccard similarity of each tf-idf search with each product column.\n",
    "title_jaccardSim_train = jaccardSimilarity('product_title_wcDict', trainData_dict)\n",
    "descr_jaccardSim_train = jaccardSimilarity('product_description_wcDict', trainData_dict)\n",
    "attributes_jaccardSim_train = jaccardSimilarity('attributes_wcDict', trainData_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newly constructed data frame - train data.\n",
    "### Mapping from trainData_dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:41:26.642940Z",
     "iopub.status.busy": "2024-02-22T22:41:26.642572Z",
     "iopub.status.idle": "2024-02-22T22:41:26.963366Z",
     "shell.execute_reply": "2024-02-22T22:41:26.962369Z",
     "shell.execute_reply.started": "2024-02-22T22:41:26.642911Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_cosineSim</th>\n",
       "      <th>descr_cosineSim</th>\n",
       "      <th>attributes_cosineSim</th>\n",
       "      <th>title_jaccardSim</th>\n",
       "      <th>descr_jaccardSim</th>\n",
       "      <th>attributes_jaccardSim</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.102917</td>\n",
       "      <td>0.027439</td>\n",
       "      <td>0.039460</td>\n",
       "      <td>0.102917</td>\n",
       "      <td>0.027439</td>\n",
       "      <td>0.039460</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051113</td>\n",
       "      <td>0.047228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051113</td>\n",
       "      <td>0.047228</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.083094</td>\n",
       "      <td>0.032615</td>\n",
       "      <td>0.037649</td>\n",
       "      <td>0.083094</td>\n",
       "      <td>0.032615</td>\n",
       "      <td>0.037649</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.111781</td>\n",
       "      <td>0.042630</td>\n",
       "      <td>0.037535</td>\n",
       "      <td>0.111781</td>\n",
       "      <td>0.042630</td>\n",
       "      <td>0.037535</td>\n",
       "      <td>2.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   title_cosineSim  descr_cosineSim  attributes_cosineSim  title_jaccardSim  \\\n",
       "0         0.102917         0.027439              0.039460          0.102917   \n",
       "1         0.000000         0.000000              0.000000          0.000000   \n",
       "2         0.000000         0.051113              0.047228          0.000000   \n",
       "3         0.083094         0.032615              0.037649          0.083094   \n",
       "4         0.111781         0.042630              0.037535          0.111781   \n",
       "\n",
       "   descr_jaccardSim  attributes_jaccardSim  relevance  \n",
       "0          0.027439               0.039460       3.00  \n",
       "1          0.000000               0.000000       2.50  \n",
       "2          0.051113               0.047228       3.00  \n",
       "3          0.032615               0.037649       2.33  \n",
       "4          0.042630               0.037535       2.67  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a DataFrame using trainData_dict as a base\n",
    "trainData_Sim = trainData_dict.copy()\n",
    "\n",
    "#Add the cosine similarity scores as new columns\n",
    "trainData_Sim['title_cosineSim'] = trainData_Sim.index.map(title_cosineSim_train)\n",
    "trainData_Sim['descr_cosineSim'] = trainData_Sim.index.map(descr_cosineSim_train)\n",
    "trainData_Sim['attributes_cosineSim'] = trainData_Sim.index.map(attributes_cosineSim_train)\n",
    "\n",
    "trainData_Sim['title_jaccardSim'] = trainData_Sim.index.map(title_cosineSim_train)\n",
    "trainData_Sim['descr_jaccardSim'] = trainData_Sim.index.map(descr_cosineSim_train)\n",
    "trainData_Sim['attributes_jaccardSim'] = trainData_Sim.index.map(attributes_cosineSim_train)\n",
    "\n",
    "#Add Target column.\n",
    "trainData_Sim = pd.concat([trainData_Sim, trainTarget], axis=1)\n",
    "\n",
    "#Drop oroginal columns.\n",
    "trainData_Sim = trainData_Sim.drop(columns=['product_uid', 'product_title_wcDict', 'search_term_wcDict', 'product_description_wcDict', 'attributes_wcDict'])\n",
    "\n",
    "trainData_Sim.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BASIC regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T23:03:49.119702Z",
     "iopub.status.busy": "2024-02-22T23:03:49.119332Z",
     "iopub.status.idle": "2024-02-22T23:03:49.152594Z",
     "shell.execute_reply": "2024-02-22T23:03:49.150867Z",
     "shell.execute_reply.started": "2024-02-22T23:03:49.119673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.2730131356531418\n",
      "Root Mean Squared Error: 0.5225065891002159\n",
      "R-squared: 0.0425127446865714\n"
     ]
    }
   ],
   "source": [
    "trainPredictors = trainData_Sim[['title_cosineSim', 'descr_cosineSim', 'attributes_cosineSim',\n",
    "               'title_jaccardSim', 'descr_jaccardSim', 'attributes_jaccardSim']]\n",
    "\n",
    "#Extract target variable\n",
    "targetTrain = trainData_Sim['relevance']\n",
    "\n",
    "#Initialize and train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(trainPredictors, targetTrain)\n",
    "\n",
    "#Make predictions on the entire dataset\n",
    "predictionsTrain = model.predict(trainPredictors)\n",
    "\n",
    "#Evaluate the model\n",
    "mse = mean_squared_error(targetTrain, predictionsTrain)\n",
    "rmse = np.sqrt(mse)\n",
    "r_squared = r2_score(targetTrain, predictionsTrain)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(f\"R-squared: {r_squared}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune & Enhance Regression Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T23:03:52.908155Z",
     "iopub.status.busy": "2024-02-22T23:03:52.907191Z",
     "iopub.status.idle": "2024-02-22T23:03:52.913613Z",
     "shell.execute_reply": "2024-02-22T23:03:52.912573Z",
     "shell.execute_reply.started": "2024-02-22T23:03:52.908097Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = trainData_Sim.drop('relevance', axis=1)\n",
    "y_train = trainData_Sim['relevance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression, Random Forest Regressor, XGBoost, and Support Vector Regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T23:03:55.452060Z",
     "iopub.status.busy": "2024-02-22T23:03:55.451381Z",
     "iopub.status.idle": "2024-02-22T23:03:55.456742Z",
     "shell.execute_reply": "2024-02-22T23:03:55.455716Z",
     "shell.execute_reply.started": "2024-02-22T23:03:55.452026Z"
    }
   },
   "outputs": [],
   "source": [
    "#Commenting out XGBoost regressor model and SVR since they take too long and do not provide a significant increase in RMSE on train data.\n",
    "#Define models\n",
    "models = [\n",
    "    ('Linear Regression', LinearRegression()),\n",
    "    ('Random Forest Regressor', RandomForestRegressor()) #,\n",
    "    #('XGBoost', XGBRegressor()),\n",
    "    #('Support Vector Regressor', SVR())\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define parameter grids for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T23:03:58.784241Z",
     "iopub.status.busy": "2024-02-22T23:03:58.783248Z",
     "iopub.status.idle": "2024-02-22T23:03:58.789101Z",
     "shell.execute_reply": "2024-02-22T23:03:58.788020Z",
     "shell.execute_reply.started": "2024-02-22T23:03:58.784201Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grids = [\n",
    "    {},  #No hyperparameter for Linear Regression.\n",
    "    {'n_estimators': [10, 50, 100], 'max_depth': [None, 5, 10]}   # Random Forest   \n",
    "    #Running XG Boost takes 2 hours\n",
    "    # {'n_estimators': [100, 200, 300], 'learning_rate': [0.01, 0.1, 0.3]}   # XGBoost\n",
    "    \n",
    "    #Running SVR takes 4 hours \n",
    "    #{'kernel': ['linear', 'poly', 'rbf'], 'C': [0.1, 1, 10]}# SVR\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T23:04:44.430967Z",
     "iopub.status.busy": "2024-02-22T23:04:44.430083Z",
     "iopub.status.idle": "2024-02-22T23:09:55.213921Z",
     "shell.execute_reply": "2024-02-22T23:09:55.212859Z",
     "shell.execute_reply.started": "2024-02-22T23:04:44.430932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search for Linear Regression...\n",
      "Best parameters found: {}\n",
      "Best mean squared error: 0.2870134145475407\n",
      "\n",
      "Grid search for Random Forest Regressor...\n",
      "Best parameters found: {'max_depth': 5, 'n_estimators': 50}\n",
      "Best mean squared error: 0.2780781233810384\n",
      "\n",
      "Best model: RandomForestRegressor(max_depth=5, n_estimators=50)\n",
      "Best mean squared error: 0.2780781233810384\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_mse = float('inf')\n",
    "\n",
    "#Performing grid search for each model\n",
    "for (name, tuneModel), param_grid in zip(models, param_grids):\n",
    "    print(f\"Grid search for {name}...\")\n",
    "    grid_search = GridSearchCV(tuneModel, param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    #Get best model\n",
    "    if -grid_search.best_score_ < best_mse:\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_mse = -grid_search.best_score_\n",
    "\n",
    "    print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "    print(f\"Best mean squared error: {-grid_search.best_score_}\")\n",
    "    print()\n",
    "\n",
    "print(f\"Best model: {best_model}\")\n",
    "print(f\"Best mean squared error: {best_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Test Data**\n",
    "### ---process Test Set--- EXACTLY SAME as trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-19T20:33:41.183719Z",
     "iopub.status.busy": "2024-02-19T20:33:41.183100Z",
     "iopub.status.idle": "2024-02-19T20:33:41.229804Z",
     "shell.execute_reply": "2024-02-19T20:33:41.227643Z",
     "shell.execute_reply.started": "2024-02-19T20:33:41.183681Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>product_title</th>\n",
       "      <th>search_term</th>\n",
       "      <th>product_description</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>100001</td>\n",
       "      <td>[simpson, strongti, 12gaug, angl]</td>\n",
       "      <td>[metal, l, bracket]</td>\n",
       "      <td>[angl, make, joint, stronger, also, provid, co...</td>\n",
       "      <td>[bullet01, versatil, connector, variou, 90, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>100001</td>\n",
       "      <td>[simpson, strongti, 12gaug, angl]</td>\n",
       "      <td>[simpson, sku, abl]</td>\n",
       "      <td>[angl, make, joint, stronger, also, provid, co...</td>\n",
       "      <td>[bullet01, versatil, connector, variou, 90, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>100001</td>\n",
       "      <td>[simpson, strongti, 12gaug, angl]</td>\n",
       "      <td>[simpson, strong, tie]</td>\n",
       "      <td>[angl, make, joint, stronger, also, provid, co...</td>\n",
       "      <td>[bullet01, versatil, connector, variou, 90, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>100001</td>\n",
       "      <td>[simpson, strongti, 12gaug, angl]</td>\n",
       "      <td>[simpson, strong, tie, hcc668]</td>\n",
       "      <td>[angl, make, joint, stronger, also, provid, co...</td>\n",
       "      <td>[bullet01, versatil, connector, variou, 90, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>100003</td>\n",
       "      <td>[sterl, ensembl, 3314, x, 60, x, 7514, bath, s...</td>\n",
       "      <td>[bath, shower, kit]</td>\n",
       "      <td>[classic, architectur, meet, contemporari, des...</td>\n",
       "      <td>[builtin, flang, ye, bullet01, slightli, narro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  product_uid                                      product_title  \\\n",
       "0   4       100001                  [simpson, strongti, 12gaug, angl]   \n",
       "1   5       100001                  [simpson, strongti, 12gaug, angl]   \n",
       "2   6       100001                  [simpson, strongti, 12gaug, angl]   \n",
       "3   7       100001                  [simpson, strongti, 12gaug, angl]   \n",
       "4  10       100003  [sterl, ensembl, 3314, x, 60, x, 7514, bath, s...   \n",
       "\n",
       "                      search_term  \\\n",
       "0             [metal, l, bracket]   \n",
       "1             [simpson, sku, abl]   \n",
       "2          [simpson, strong, tie]   \n",
       "3  [simpson, strong, tie, hcc668]   \n",
       "4             [bath, shower, kit]   \n",
       "\n",
       "                                 product_description  \\\n",
       "0  [angl, make, joint, stronger, also, provid, co...   \n",
       "1  [angl, make, joint, stronger, also, provid, co...   \n",
       "2  [angl, make, joint, stronger, also, provid, co...   \n",
       "3  [angl, make, joint, stronger, also, provid, co...   \n",
       "4  [classic, architectur, meet, contemporari, des...   \n",
       "\n",
       "                                          attributes  \n",
       "0  [bullet01, versatil, connector, variou, 90, co...  \n",
       "1  [bullet01, versatil, connector, variou, 90, co...  \n",
       "2  [bullet01, versatil, connector, variou, 90, co...  \n",
       "3  [bullet01, versatil, connector, variou, 90, co...  \n",
       "4  [builtin, flang, ye, bullet01, slightli, narro...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#112,067 rows\n",
    "testData.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRODUCT DATA\n",
    "### Convert to term frequency dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:43:47.327054Z",
     "iopub.status.busy": "2024-02-22T22:43:47.326702Z",
     "iopub.status.idle": "2024-02-22T22:43:52.661649Z",
     "shell.execute_reply": "2024-02-22T22:43:52.660669Z",
     "shell.execute_reply.started": "2024-02-22T22:43:47.327028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_uid</th>\n",
       "      <th>product_title_wcDict</th>\n",
       "      <th>search_term_wcDict</th>\n",
       "      <th>product_description_wcDict</th>\n",
       "      <th>attributes_wcDict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>{'simpson': 1, 'strongti': 1, '12gaug': 1, 'an...</td>\n",
       "      <td>{'metal': 1, 'l': 1, 'bracket': 1}</td>\n",
       "      <td>{'angl': 3, 'make': 1, 'joint': 2, 'stronger':...</td>\n",
       "      <td>{'bullet01': 1, 'versatil': 1, 'connector': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>{'simpson': 1, 'strongti': 1, '12gaug': 1, 'an...</td>\n",
       "      <td>{'simpson': 1, 'sku': 1, 'abl': 1}</td>\n",
       "      <td>{'angl': 3, 'make': 1, 'joint': 2, 'stronger':...</td>\n",
       "      <td>{'bullet01': 1, 'versatil': 1, 'connector': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100001</td>\n",
       "      <td>{'simpson': 1, 'strongti': 1, '12gaug': 1, 'an...</td>\n",
       "      <td>{'simpson': 1, 'strong': 1, 'tie': 1}</td>\n",
       "      <td>{'angl': 3, 'make': 1, 'joint': 2, 'stronger':...</td>\n",
       "      <td>{'bullet01': 1, 'versatil': 1, 'connector': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100001</td>\n",
       "      <td>{'simpson': 1, 'strongti': 1, '12gaug': 1, 'an...</td>\n",
       "      <td>{'simpson': 1, 'strong': 1, 'tie': 1, 'hcc668'...</td>\n",
       "      <td>{'angl': 3, 'make': 1, 'joint': 2, 'stronger':...</td>\n",
       "      <td>{'bullet01': 1, 'versatil': 1, 'connector': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100003</td>\n",
       "      <td>{'sterl': 1, 'ensembl': 1, '3314': 1, 'x': 2, ...</td>\n",
       "      <td>{'bath': 1, 'shower': 1, 'kit': 1}</td>\n",
       "      <td>{'classic': 1, 'architectur': 1, 'meet': 1, 'c...</td>\n",
       "      <td>{'builtin': 1, 'flang': 1, 'ye': 1, 'bullet01'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_uid                               product_title_wcDict  \\\n",
       "0       100001  {'simpson': 1, 'strongti': 1, '12gaug': 1, 'an...   \n",
       "1       100001  {'simpson': 1, 'strongti': 1, '12gaug': 1, 'an...   \n",
       "2       100001  {'simpson': 1, 'strongti': 1, '12gaug': 1, 'an...   \n",
       "3       100001  {'simpson': 1, 'strongti': 1, '12gaug': 1, 'an...   \n",
       "4       100003  {'sterl': 1, 'ensembl': 1, '3314': 1, 'x': 2, ...   \n",
       "\n",
       "                                  search_term_wcDict  \\\n",
       "0                 {'metal': 1, 'l': 1, 'bracket': 1}   \n",
       "1                 {'simpson': 1, 'sku': 1, 'abl': 1}   \n",
       "2              {'simpson': 1, 'strong': 1, 'tie': 1}   \n",
       "3  {'simpson': 1, 'strong': 1, 'tie': 1, 'hcc668'...   \n",
       "4                 {'bath': 1, 'shower': 1, 'kit': 1}   \n",
       "\n",
       "                          product_description_wcDict  \\\n",
       "0  {'angl': 3, 'make': 1, 'joint': 2, 'stronger':...   \n",
       "1  {'angl': 3, 'make': 1, 'joint': 2, 'stronger':...   \n",
       "2  {'angl': 3, 'make': 1, 'joint': 2, 'stronger':...   \n",
       "3  {'angl': 3, 'make': 1, 'joint': 2, 'stronger':...   \n",
       "4  {'classic': 1, 'architectur': 1, 'meet': 1, 'c...   \n",
       "\n",
       "                                   attributes_wcDict  \n",
       "0  {'bullet01': 1, 'versatil': 1, 'connector': 1,...  \n",
       "1  {'bullet01': 1, 'versatil': 1, 'connector': 1,...  \n",
       "2  {'bullet01': 1, 'versatil': 1, 'connector': 1,...  \n",
       "3  {'bullet01': 1, 'versatil': 1, 'connector': 1,...  \n",
       "4  {'builtin': 1, 'flang': 1, 'ye': 1, 'bullet01'...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData_dict = testData\n",
    "\n",
    "convertColumns = ['product_title', 'search_term', 'product_description', 'attributes']\n",
    "\n",
    "for column in convertColumns:\n",
    "    #Convert each cell ito a dictionary of word counts.\n",
    "    testData_dict[column + '_wcDict'] = testData_dict[column].apply(lambda x: dict(Counter(x)))\n",
    "\n",
    "#Drop oroginal columns.\n",
    "testData_dict = testData_dict.drop(columns=['id', 'product_title', 'search_term', 'product_description', 'attributes'])\n",
    "testData_dict.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert PRODUCT columns to inverted index dictionaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:43:56.909561Z",
     "iopub.status.busy": "2024-02-22T22:43:56.909202Z",
     "iopub.status.idle": "2024-02-22T22:44:55.661725Z",
     "shell.execute_reply": "2024-02-22T22:44:55.660911Z",
     "shell.execute_reply.started": "2024-02-22T22:43:56.909531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique product: 74909\n",
      "Total number of unique product: 74909\n",
      "Total number of unique product: 74909\n"
     ]
    }
   ],
   "source": [
    "#Generate inverted index for each product column.\n",
    "title_invIndex_test = generate_invIndex('product_title_wcDict', testData_dict)\n",
    "descr_invIndex_test = generate_invIndex('product_description_wcDict', testData_dict)\n",
    "attributes_invIndex_test = generate_invIndex('attributes_wcDict', testData_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute component vector length of each PRODUCT column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:45:12.396619Z",
     "iopub.status.busy": "2024-02-22T22:45:12.395889Z",
     "iopub.status.idle": "2024-02-22T22:45:16.931340Z",
     "shell.execute_reply": "2024-02-22T22:45:16.930547Z",
     "shell.execute_reply.started": "2024-02-22T22:45:12.396584Z"
    }
   },
   "outputs": [],
   "source": [
    "#Get vector length for each product column.\n",
    "title_vecLength_test = computeVectorLength_product(title_invIndex_test)\n",
    "descr_vecLength_test = computeVectorLength_product(descr_invIndex_test)\n",
    "attributes_vecLength_test = computeVectorLength_product(attributes_invIndex_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:45:16.933056Z",
     "iopub.status.busy": "2024-02-22T22:45:16.932770Z",
     "iopub.status.idle": "2024-02-22T22:45:16.938253Z",
     "shell.execute_reply": "2024-02-22T22:45:16.937398Z",
     "shell.execute_reply.started": "2024-02-22T22:45:16.933030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Title Vector Length:\n",
      "18.949368613584586\n"
     ]
    }
   ],
   "source": [
    "print(\"Product Title Vector Length:\")\n",
    "print(title_vecLength_test[100001])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEARCH DATA\n",
    "### Convert SEARCH column to inverted index dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:45:20.145167Z",
     "iopub.status.busy": "2024-02-22T22:45:20.144824Z",
     "iopub.status.idle": "2024-02-22T22:45:41.325144Z",
     "shell.execute_reply": "2024-02-22T22:45:41.324176Z",
     "shell.execute_reply.started": "2024-02-22T22:45:20.145140Z"
    }
   },
   "outputs": [],
   "source": [
    "#Get search tf-idf with respect to each product column.\n",
    "title_tf_idfSearch_test = tf_idfSearch(title_invIndex_test, testData_dict)\n",
    "descr_tf_idfSearch_test = tf_idfSearch(descr_invIndex_test, testData_dict)\n",
    "attributes_tf_idfSearch_test = tf_idfSearch(attributes_invIndex_test, testData_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute SEARCH score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:45:51.127787Z",
     "iopub.status.busy": "2024-02-22T22:45:51.127440Z",
     "iopub.status.idle": "2024-02-22T22:45:51.331571Z",
     "shell.execute_reply": "2024-02-22T22:45:51.330757Z",
     "shell.execute_reply.started": "2024-02-22T22:45:51.127759Z"
    }
   },
   "outputs": [],
   "source": [
    "#Get search score tf-idf with respect to each product column.\n",
    "title_searchScore_test = product_searchScore(title_tf_idfSearch_test)\n",
    "descr_searchScore_test = product_searchScore(descr_tf_idfSearch_test)\n",
    "attributes_searchScore_test = product_searchScore(attributes_tf_idfSearch_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:46:49.348870Z",
     "iopub.status.busy": "2024-02-22T22:46:49.348071Z",
     "iopub.status.idle": "2024-02-22T22:46:49.355178Z",
     "shell.execute_reply": "2024-02-22T22:46:49.354267Z",
     "shell.execute_reply.started": "2024-02-22T22:46:49.348836Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Title Search score - TEST data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8036.937356490582"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Product Title Search score - TEST data:\")\n",
    "title_searchScore_test[74066]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute component vector length of SEARCH column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:47:22.104246Z",
     "iopub.status.busy": "2024-02-22T22:47:22.103676Z",
     "iopub.status.idle": "2024-02-22T22:47:22.468575Z",
     "shell.execute_reply": "2024-02-22T22:47:22.467530Z",
     "shell.execute_reply.started": "2024-02-22T22:47:22.104217Z"
    }
   },
   "outputs": [],
   "source": [
    "#Get vector length of each tf-idf search, respect to each product column.\n",
    "title_search_vecLength_test = computeVectorLength_search(title_tf_idfSearch_test)\n",
    "descr_search_vecLength_test = computeVectorLength_search(descr_tf_idfSearch_test)\n",
    "attributes_search_vecLength_test = computeVectorLength_search(attributes_tf_idfSearch_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:47:27.576933Z",
     "iopub.status.busy": "2024-02-22T22:47:27.576587Z",
     "iopub.status.idle": "2024-02-22T22:47:32.905453Z",
     "shell.execute_reply": "2024-02-22T22:47:32.904448Z",
     "shell.execute_reply.started": "2024-02-22T22:47:27.576906Z"
    }
   },
   "outputs": [],
   "source": [
    "#Get cosine similarity of each tf-idf search with each product column.\n",
    "title_cosineSim_test = cosineSimilarity(title_search_vecLength_test, title_vecLength_test,title_searchScore_test, testData_dict)\n",
    "descr_cosineSim_test = cosineSimilarity(descr_search_vecLength_test, descr_vecLength_test, descr_searchScore_test, testData_dict)\n",
    "attributes_cosineSim_test = cosineSimilarity(attributes_search_vecLength_test,attributes_vecLength_test, attributes_searchScore_test, testData_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:47:51.881084Z",
     "iopub.status.busy": "2024-02-22T22:47:51.880735Z",
     "iopub.status.idle": "2024-02-22T22:47:51.887567Z",
     "shell.execute_reply": "2024-02-22T22:47:51.886578Z",
     "shell.execute_reply.started": "2024-02-22T22:47:51.881056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112067"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make sure dictionary generated properly, len = total number of rows. \n",
    "len(title_cosineSim_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Jaccard similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:47:56.342654Z",
     "iopub.status.busy": "2024-02-22T22:47:56.342294Z",
     "iopub.status.idle": "2024-02-22T22:48:18.513728Z",
     "shell.execute_reply": "2024-02-22T22:48:18.512596Z",
     "shell.execute_reply.started": "2024-02-22T22:47:56.342625Z"
    }
   },
   "outputs": [],
   "source": [
    "#Get jaccard similarity of each tf-idf search with each product column.\n",
    "title_jaccardSim_test = jaccardSimilarity('product_title_wcDict', testData_dict)\n",
    "descr_jaccardSim_test = jaccardSimilarity('product_description_wcDict', testData_dict)\n",
    "attributes_jaccardSim_test = jaccardSimilarity('attributes_wcDict', testData_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newly constructed data frame - test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:48:18.516601Z",
     "iopub.status.busy": "2024-02-22T22:48:18.515721Z",
     "iopub.status.idle": "2024-02-22T22:48:18.971715Z",
     "shell.execute_reply": "2024-02-22T22:48:18.970782Z",
     "shell.execute_reply.started": "2024-02-22T22:48:18.516564Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_cosineSim</th>\n",
       "      <th>descr_cosineSim</th>\n",
       "      <th>attributes_cosineSim</th>\n",
       "      <th>title_jaccardSim</th>\n",
       "      <th>descr_jaccardSim</th>\n",
       "      <th>attributes_jaccardSim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.052772</td>\n",
       "      <td>0.013910</td>\n",
       "      <td>0.020303</td>\n",
       "      <td>0.052772</td>\n",
       "      <td>0.013910</td>\n",
       "      <td>0.020303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.052772</td>\n",
       "      <td>0.013910</td>\n",
       "      <td>0.024464</td>\n",
       "      <td>0.052772</td>\n",
       "      <td>0.013910</td>\n",
       "      <td>0.024464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.052772</td>\n",
       "      <td>0.013910</td>\n",
       "      <td>0.025507</td>\n",
       "      <td>0.052772</td>\n",
       "      <td>0.013910</td>\n",
       "      <td>0.025507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.091720</td>\n",
       "      <td>0.030435</td>\n",
       "      <td>0.031380</td>\n",
       "      <td>0.091720</td>\n",
       "      <td>0.030435</td>\n",
       "      <td>0.031380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   title_cosineSim  descr_cosineSim  attributes_cosineSim  title_jaccardSim  \\\n",
       "0         0.000000         0.000000              0.000000          0.000000   \n",
       "1         0.052772         0.013910              0.020303          0.052772   \n",
       "2         0.052772         0.013910              0.024464          0.052772   \n",
       "3         0.052772         0.013910              0.025507          0.052772   \n",
       "4         0.091720         0.030435              0.031380          0.091720   \n",
       "\n",
       "   descr_jaccardSim  attributes_jaccardSim  \n",
       "0          0.000000               0.000000  \n",
       "1          0.013910               0.020303  \n",
       "2          0.013910               0.024464  \n",
       "3          0.013910               0.025507  \n",
       "4          0.030435               0.031380  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a DataFrame using trainData_dict as a base\n",
    "testData_Sim = testData_dict.copy()\n",
    "\n",
    "# Add the cosine similarity scores as new columns\n",
    "testData_Sim['title_cosineSim'] = testData_Sim.index.map(title_cosineSim_test)\n",
    "testData_Sim['descr_cosineSim'] = testData_Sim.index.map(descr_cosineSim_test)\n",
    "testData_Sim['attributes_cosineSim'] = testData_Sim.index.map(attributes_cosineSim_test)\n",
    "\n",
    "testData_Sim['title_jaccardSim'] = testData_Sim.index.map(title_cosineSim_test)\n",
    "testData_Sim['descr_jaccardSim'] = testData_Sim.index.map(descr_cosineSim_test)\n",
    "testData_Sim['attributes_jaccardSim'] = testData_Sim.index.map(attributes_cosineSim_test)\n",
    "\n",
    "#Drop oroginal columns.\n",
    "testData_Sim = testData_Sim.drop(columns=['product_uid', 'product_title_wcDict', 'search_term_wcDict', 'product_description_wcDict', 'attributes_wcDict'])\n",
    "\n",
    "testData_Sim.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T22:48:22.551235Z",
     "iopub.status.busy": "2024-02-22T22:48:22.550528Z",
     "iopub.status.idle": "2024-02-22T22:48:22.556828Z",
     "shell.execute_reply": "2024-02-22T22:48:22.555827Z",
     "shell.execute_reply.started": "2024-02-22T22:48:22.551205Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112067, 6)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData_Sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction using test set both BASIC and best models. Write prediction to a csv file.\n",
    "### Best Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T23:11:23.799689Z",
     "iopub.status.busy": "2024-02-22T23:11:23.799199Z",
     "iopub.status.idle": "2024-02-22T23:11:23.978385Z",
     "shell.execute_reply": "2024-02-22T23:11:23.977611Z",
     "shell.execute_reply.started": "2024-02-22T23:11:23.799660Z"
    }
   },
   "outputs": [],
   "source": [
    "#Extract features from the test set,\n",
    "X_test = testData_Sim\n",
    "\n",
    "#Make predictions on the test set,\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T23:11:25.406427Z",
     "iopub.status.busy": "2024-02-22T23:11:25.405737Z",
     "iopub.status.idle": "2024-02-22T23:11:25.602061Z",
     "shell.execute_reply": "2024-02-22T23:11:25.601050Z",
     "shell.execute_reply.started": "2024-02-22T23:11:25.406396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  relevance\n",
      "0   4       2.02\n",
      "1   5       2.43\n",
      "2   6       2.40\n",
      "3   7       2.39\n",
      "4  10       2.43\n",
      "5  12       2.31\n",
      "6  13       2.29\n",
      "7  14       2.34\n",
      "8  15       2.32\n",
      "9  24       2.30\n",
      "Successfully save - Best Model!\n"
     ]
    }
   ],
   "source": [
    "bestModel_predictionsTest_df = pd.DataFrame({'id': testData['id'], 'relevance': y_pred.round(2)})\n",
    "print(bestModel_predictionsTest_df.head(10))\n",
    "bestModel_predictionsTest_df.to_csv('test_predictions_best_model.csv', index=False)\n",
    "print(f'Successfully save - Best Model!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-22T23:11:29.682648Z",
     "iopub.status.busy": "2024-02-22T23:11:29.681601Z",
     "iopub.status.idle": "2024-02-22T23:11:29.960042Z",
     "shell.execute_reply": "2024-02-22T23:11:29.959166Z",
     "shell.execute_reply.started": "2024-02-22T23:11:29.682612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  relevance\n",
      "0   4       2.26\n",
      "1   5       2.30\n",
      "2   6       2.29\n",
      "3   7       2.29\n",
      "4  10       2.34\n",
      "5  12       2.26\n",
      "6  13       2.35\n",
      "7  14       2.40\n",
      "8  15       2.38\n",
      "9  24       2.31\n",
      "Successfully save - Basic Model!\n"
     ]
    }
   ],
   "source": [
    "#Extract features from the test set\n",
    "testPredictors = testData_Sim[['title_cosineSim', 'descr_cosineSim', 'attributes_cosineSim',\n",
    "                               'title_jaccardSim', 'descr_jaccardSim', 'attributes_jaccardSim']]\n",
    "\n",
    "#Make predictions on the test set\n",
    "basicModel_predictionsTest = model.predict(testPredictors)\n",
    "basicModel_predictionsTest_df = pd.DataFrame({'id': testData['id'], 'relevance': predictionsTest.round(2)})\n",
    "print(basicModel_predictionsTest_df.head(10))\n",
    "basicModel_predictionsTest_df.to_csv('test_predictions_basic_model.csv', index=False)\n",
    "print(f'Successfully save - Basic Model!')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7388662,
     "sourceId": 66616,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
